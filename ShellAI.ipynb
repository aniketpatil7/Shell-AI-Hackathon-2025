{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "KAXGC0pzkp65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')"
      ],
      "metadata": {
        "id": "ahk9-_U0kkAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in train.columns:\n",
        "    print(i)"
      ],
      "metadata": {
        "id": "jeCry_wHla2u",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = train.drop([f'BlendProperty{i}' for i in range(1,11)], axis=1)"
      ],
      "metadata": {
        "id": "HXDKg8_Iku3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ca3e1598",
        "collapsed": true
      },
      "source": [
        "y = train[[f'BlendProperty{i}' for i in range(1,11)]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "781754b0",
        "collapsed": true
      },
      "source": [
        "# Create new features by multiplying component fractions by their properties\n",
        "num_components = 5\n",
        "num_properties = 10\n",
        "\n",
        "X_engineered = X.copy()\n",
        "\n",
        "for i in range(1, num_components + 1):\n",
        "    for j in range(1, num_properties + 1):\n",
        "        X_engineered[f'Component{i}_fraction_x_Component{i}_Property{j}'] = X_engineered[f'Component{i}_fraction'] * X_engineered[f'Component{i}_Property{j}']\n",
        "\n",
        "display(X_engineered.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0a59106",
        "collapsed": true
      },
      "source": [
        "X_engineered_summary = X_engineered.copy()\n",
        "\n",
        "for i in range(1, num_components + 1):\n",
        "    properties = [f'Component{i}_Property{j}' for j in range(1, num_properties + 1)]\n",
        "    X_engineered_summary[f'Component{i}_Property_mean'] = X_engineered_summary[properties].mean(axis=1)\n",
        "    X_engineered_summary[f'Component{i}_Property_std'] = X_engineered_summary[properties].std(axis=1)\n",
        "    X_engineered_summary[f'Component{i}_Property_min'] = X_engineered_summary[properties].min(axis=1)\n",
        "    X_engineered_summary[f'Component{i}_Property_max'] = X_engineered_summary[properties].max(axis=1)\n",
        "    X_engineered_summary[f'Component{i}_Property_range'] = X_engineered_summary[properties].max(axis=1) - X_engineered_summary[properties].min(axis=1)\n",
        "\n",
        "display(X_engineered_summary.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cea7ee1f",
        "collapsed": true
      },
      "source": [
        "X_engineered_dominant = X_engineered.copy()\n",
        "\n",
        "X_engineered_dominant['Dominant_comp'] = X_engineered_dominant[[f'Component{i}_fraction' for i in range(1, num_components + 1)]].idxmax(axis=1).str.replace('Component', '').str.replace('_fraction', '').astype(int)\n",
        "\n",
        "display(X_engineered_dominant.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7d9fbdab"
      },
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "\n",
        "# Assuming X_engineered_summary is the final engineered feature set and y is the target DataFrame\n",
        "\n",
        "# Include dominant component feature engineering in the training data as well\n",
        "X_train_engineered_summary = X_engineered_summary.copy()\n",
        "X_train_engineered_summary['Dominant_comp'] = X_train_engineered_summary[[f'Component{i}_fraction' for i in range(1, num_components + 1)]].idxmax(axis=1).str.replace('Component', '').str.replace('_fraction', '').astype(int)\n",
        "\n",
        "\n",
        "# Create and train a LightGBM model for each target variable\n",
        "lgbm_models = {}\n",
        "for col in y.columns:\n",
        "    print(f\"Training LightGBM model for {col}...\")\n",
        "    model = lgb.LGBMRegressor(random_state=42)\n",
        "    model.fit(X_train_engineered_summary, y[col])\n",
        "    lgbm_models[col] = model\n",
        "\n",
        "print(\"LightGBM model training complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fd98b4b"
      },
      "source": [
        "# Apply the same feature engineering to the test data\n",
        "num_components = 5\n",
        "num_properties = 10\n",
        "\n",
        "X_test_engineered_summary = test.copy()\n",
        "\n",
        "# Drop the 'ID' column from the test data before feature engineering\n",
        "if 'ID' in X_test_engineered_summary.columns:\n",
        "    X_test_engineered_summary = X_test_engineered_summary.drop('ID', axis=1)\n",
        "\n",
        "\n",
        "for i in range(1, num_components + 1):\n",
        "    for j in range(1, num_properties + 1):\n",
        "        X_test_engineered_summary[f'Component{i}_fraction_x_Component{i}_Property{j}'] = X_test_engineered_summary[f'Component{i}_fraction'] * X_test_engineered_summary[f'Component{i}_Property{j}']\n",
        "\n",
        "for i in range(1, num_components + 1):\n",
        "    properties = [f'Component{i}_Property{j}' for j in range(1, num_properties + 1)]\n",
        "    X_test_engineered_summary[f'Component{i}_Property_mean'] = X_test_engineered_summary[properties].mean(axis=1)\n",
        "    X_test_engineered_summary[f'Component{i}_Property_std'] = X_test_engineered_summary[properties].std(axis=1)\n",
        "    X_test_engineered_summary[f'Component{i}_Property_min'] = X_test_engineered_summary[properties].min(axis=1)\n",
        "    X_test_engineered_summary[f'Component{i}_Property_max'] = X_test_engineered_summary[properties].max(axis=1)\n",
        "    X_test_engineered_summary[f'Component{i}_Property_range'] = X_test_engineered_summary[properties].max(axis=1) - X_test_engineered_summary[properties].min(axis=1)\n",
        "\n",
        "X_test_engineered_summary['Dominant_comp'] = X_test_engineered_summary[[f'Component{i}_fraction' for i in range(1, num_components + 1)]].idxmax(axis=1).str.replace('Component', '').str.replace('_fraction', '').astype(int)\n",
        "\n",
        "# Make predictions on the test data for each blend property\n",
        "test_predictions = {}\n",
        "for col in y.columns:\n",
        "    test_predictions[col] = lgbm_models[col].predict(X_test_engineered_summary)\n",
        "\n",
        "print(\"Predictions on test data complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1432e97"
      },
      "source": [
        "# Create a submission DataFrame\n",
        "submission_df = pd.DataFrame(test['ID'])\n",
        "\n",
        "for col in y.columns:\n",
        "    submission_df[col] = test_predictions[col]\n",
        "\n",
        "# Save the submission file\n",
        "submission_df.to_csv('submission_lgbm.csv', index=False)\n",
        "\n",
        "print(\"Submission file 'submission.csv' created successfully!\")\n",
        "print(\"The accuracy was 71.42\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "id": "lVNoCA1Hm9G6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6c63d412"
      },
      "source": [
        "from catboost import CatBoostRegressor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20dcb6ea"
      },
      "source": [
        "# Initialize a dictionary to store trained CatBoost models\n",
        "catboost_models = {}\n",
        "\n",
        "# Iterate through each target column in the y DataFrame\n",
        "for col in y.columns:\n",
        "    print(f\"Training CatBoost model for {col}...\")\n",
        "    # Instantiate a CatBoostRegressor model\n",
        "    model = CatBoostRegressor(random_state=42, verbose=0)  # verbose=0 to suppress output\n",
        "    # Fit the model to the engineered training data and the current target\n",
        "    model.fit(X_train_engineered_summary, y[col])\n",
        "    # Store the trained model in the dictionary\n",
        "    catboost_models[col] = model\n",
        "\n",
        "print(\"CatBoost model training complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7737edca"
      },
      "source": [
        "test_predictions_catboost = {}\n",
        "for col in catboost_models:\n",
        "    test_predictions_catboost[col] = catboost_models[col].predict(X_test_engineered_summary)\n",
        "\n",
        "print(\"Predictions on test data complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8ba052d"
      },
      "source": [
        "submission_df = pd.DataFrame(test['ID'])\n",
        "\n",
        "for col in test_predictions_catboost:\n",
        "    submission_df[col] = test_predictions_catboost[col]\n",
        "\n",
        "submission_df.to_csv('submission_cat.csv', index=False)\n",
        "\n",
        "print(\"Submission file 'submission.csv' created successfully!\")\n",
        "print(\"the accuracy is 79%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5e94040"
      },
      "source": [
        "import xgboost as xgb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf78f334"
      },
      "source": [
        "# Initialize a dictionary to store trained XGBoost models\n",
        "xgboost_models = {}\n",
        "\n",
        "# Iterate through each target column in the y DataFrame\n",
        "for col in y.columns:\n",
        "    print(f\"Training XGBoost model for {col}...\")\n",
        "    # Instantiate an XGBoostRegressor model\n",
        "    model = xgb.XGBRegressor(random_state=42)\n",
        "    # Fit the model to the engineered training data and the current target\n",
        "    model.fit(X_train_engineered_summary, y[col])\n",
        "    # Store the trained model in the dictionary\n",
        "    xgboost_models[col] = model\n",
        "\n",
        "print(\"XGBoost model training complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "322c2351"
      },
      "source": [
        "test_predictions_xgboost = {}\n",
        "for col in xgboost_models:\n",
        "    test_predictions_xgboost[col] = xgboost_models[col].predict(X_test_engineered_summary)\n",
        "\n",
        "print(\"Predictions on test data complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cc288f1"
      },
      "source": [
        "submission_df = pd.DataFrame(test['ID'])\n",
        "\n",
        "for col in test_predictions_xgboost:\n",
        "    submission_df[col] = test_predictions_xgboost[col]\n",
        "\n",
        "submission_df.to_csv('submission_xgb.csv', index=False)\n",
        "\n",
        "print(\"Submission file 'submission.csv' created successfully!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "da5eb774"
      },
      "source": [
        "from sklearn.ensemble import HistGradientBoostingRegressor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "638eb96d"
      },
      "source": [
        "# Initialize a dictionary to store trained HistGradientBoostingRegressor models\n",
        "hgb_models = {}\n",
        "\n",
        "# Iterate through each target column in the y DataFrame\n",
        "for col in y.columns:\n",
        "    print(f\"Training HistGradientBoostingRegressor model for {col}...\")\n",
        "    # Instantiate a HistGradientBoostingRegressor model\n",
        "    model = HistGradientBoostingRegressor(random_state=42)\n",
        "    # Fit the model to the engineered training data and the current target\n",
        "    model.fit(X_train_engineered_summary, y[col])\n",
        "    # Store the trained model in the dictionary\n",
        "    hgb_models[col] = model\n",
        "\n",
        "print(\"HistGradientBoostingRegressor model training complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfb98c0e"
      },
      "source": [
        "test_predictions_hgb = {}\n",
        "for col in hgb_models:\n",
        "    test_predictions_hgb[col] = hgb_models[col].predict(X_test_engineered_summary)\n",
        "\n",
        "print(\"Predictions on test data complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ff10291"
      },
      "source": [
        "submission_df = pd.DataFrame(test['ID'])\n",
        "\n",
        "for col in test_predictions_hgb:\n",
        "    submission_df[col] = test_predictions_hgb[col]\n",
        "\n",
        "submission_df.to_csv('submission_hgb.csv', index=False)\n",
        "\n",
        "print(\"Submission file 'submission.csv' created successfully!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65a15d94"
      },
      "source": [
        "from sklearn.linear_model import Ridge"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26c3bc7b"
      },
      "source": [
        "# Initialize a dictionary to store trained Ridge models\n",
        "ridge_models = {}\n",
        "\n",
        "# Iterate through each target column in the y DataFrame\n",
        "for col in y.columns:\n",
        "    print(f\"Training Ridge model for {col}...\")\n",
        "    # Instantiate a Ridge model\n",
        "    model = Ridge(random_state=42)\n",
        "    # Fit the model to the engineered training data and the current target\n",
        "    model.fit(X_train_engineered_summary, y[col])\n",
        "    # Store the trained model in the dictionary\n",
        "    ridge_models[col] = model\n",
        "\n",
        "print(\"Ridge model training complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43771b52"
      },
      "source": [
        "test_predictions_ridge = {}\n",
        "for col in ridge_models:\n",
        "    test_predictions_ridge[col] = ridge_models[col].predict(X_test_engineered_summary)\n",
        "\n",
        "print(\"Predictions on test data complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "309df922"
      },
      "source": [
        "submission_df = pd.DataFrame(test['ID'])\n",
        "\n",
        "for col in test_predictions_ridge:\n",
        "    submission_df[col] = test_predictions_ridge[col]\n",
        "\n",
        "submission_df.to_csv('submission_ridge.csv', index=False)\n",
        "\n",
        "print(\"Submission file 'submission_ridge.csv' created successfully!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6f160a8"
      },
      "source": [
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "\n",
        "print(\"MAPE on training data for each BlendProperty (LightGBM - sklearn):\")\n",
        "for col in y.columns:\n",
        "    model = lgbm_models[col]\n",
        "    y_train_pred = model.predict(X_train_engineered_summary)\n",
        "    mape = mean_absolute_percentage_error(y[col], y_train_pred)\n",
        "    print(f\"  {col}: {mape:.2f}%\")\n",
        "\n",
        "print(\"\\nMAPE on training data for each BlendProperty (CatBoost - sklearn):\")\n",
        "for col in y.columns:\n",
        "    model = catboost_models[col]\n",
        "    y_train_pred = model.predict(X_train_engineered_summary)\n",
        "    mape = mean_absolute_percentage_error(y[col], y_train_pred)\n",
        "    print(f\"  {col}: {mape:.2f}%\")\n",
        "\n",
        "print(\"\\nMAPE on training data for each BlendProperty (XGBoost - sklearn):\")\n",
        "for col in y.columns:\n",
        "    model = xgboost_models[col]\n",
        "    y_train_pred = model.predict(X_train_engineered_summary)\n",
        "    mape = mean_absolute_percentage_error(y[col], y_train_pred)\n",
        "    print(f\"  {col}: {mape:.2f}%\")\n",
        "\n",
        "print(\"\\nMAPE on training data for each BlendProperty (HistGradientBoostingRegressor - sklearn):\")\n",
        "for col in y.columns:\n",
        "    model = hgb_models[col]\n",
        "    y_train_pred = model.predict(X_train_engineered_summary)\n",
        "    mape = mean_absolute_percentage_error(y[col], y_train_pred)\n",
        "    print(f\"  {col}: {mape:.2f}%\")\n",
        "\n",
        "print(\"\\nMAPE on training data for each BlendProperty (Ridge - sklearn):\")\n",
        "for col in y.columns:\n",
        "    model = ridge_models[col]\n",
        "    y_train_pred = model.predict(X_train_engineered_summary)\n",
        "    mape = mean_absolute_percentage_error(y[col], y_train_pred)\n",
        "    print(f\"  {col}: {mape:.2f}%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22666f17"
      },
      "source": [
        "# Load the test predictions from each model\n",
        "test_predictions_catboost_df = pd.read_csv('submission_cat.csv')\n",
        "test_predictions_ridge_df = pd.read_csv('submission_ridge.csv')\n",
        "test_predictions_lgbm_df = pd.read_csv('submission_lgbm.csv')\n",
        "test_predictions_hgb_df = pd.read_csv('submission_hgb.csv')\n",
        "\n",
        "# Store the prediction DataFrames in a dictionary\n",
        "test_predictions_dfs = {\n",
        "    'catboost': test_predictions_catboost_df,\n",
        "    'ridge': test_predictions_ridge_df,\n",
        "    'lgbm': test_predictions_lgbm_df,\n",
        "    'hgb': test_predictions_hgb_df\n",
        "}\n",
        "\n",
        "print(\"Test prediction dataframes loaded.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20ad6dee"
      },
      "source": [
        "# Create a copy of one of the loaded test prediction DataFrames to serve as the base\n",
        "ensembled_predictions_df = test_predictions_catboost_df.copy()\n",
        "\n",
        "# Define the blend property columns\n",
        "blend_property_cols = [f'BlendProperty{i}' for i in range(1, 11)]\n",
        "\n",
        "# Iterate through each blend property column\n",
        "for col in blend_property_cols:\n",
        "    # Calculate the average of the predictions from all models\n",
        "    ensembled_predictions_df[col] = (\n",
        "        test_predictions_dfs['catboost'][col] +\n",
        "        test_predictions_dfs['ridge'][col] +\n",
        "        test_predictions_dfs['lgbm'][col] +\n",
        "        test_predictions_dfs['hgb'][col]\n",
        "    ) / len(test_predictions_dfs)\n",
        "\n",
        "# Display the head of the ensembled_predictions_df\n",
        "display(ensembled_predictions_df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b549211d"
      },
      "source": [
        "# Create a submission DataFrame using the ensembled_predictions_df\n",
        "submission_df = ensembled_predictions_df.copy()\n",
        "\n",
        "# Save the submission DataFrame to a CSV file\n",
        "submission_df.to_csv('submission_ensembled.csv', index=False)\n",
        "\n",
        "print(\"Submission file 'submission_ensembled.csv' created successfully!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1d3bd71"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Define the number of splits for K-fold cross-validation\n",
        "n_splits = 5\n",
        "\n",
        "# Initialize a dictionary to store the out-of-fold predictions\n",
        "oof_predictions = {\n",
        "    'catboost': {},\n",
        "    'ridge': {},\n",
        "    'lgbm': {},\n",
        "    'hgb': {}\n",
        "}\n",
        "\n",
        "# Iterate through each blend property\n",
        "for col in y.columns:\n",
        "    print(f\"Generating out-of-fold predictions for {col}...\")\n",
        "\n",
        "    # Iterate through each base model\n",
        "    for model_name, models_dict in [('catboost', catboost_models),\n",
        "                                    ('ridge', ridge_models),\n",
        "                                    ('lgbm', lgbm_models),\n",
        "                                    ('hgb', hgb_models)]:\n",
        "\n",
        "        # Initialize an array to store OOF predictions for the current blend property and model\n",
        "        oof_preds = np.zeros(X_train_engineered_summary.shape[0])\n",
        "\n",
        "        # Initialize KFold\n",
        "        kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "        # Iterate through the splits\n",
        "        for train_index, val_index in kf.split(X_train_engineered_summary):\n",
        "            # Get training and validation data for the current split\n",
        "            X_train_fold, X_val_fold = X_train_engineered_summary.iloc[train_index], X_train_engineered_summary.iloc[val_index]\n",
        "            y_train_fold, y_val_fold = y[col].iloc[train_index], y[col].iloc[val_index]\n",
        "\n",
        "            # Get the corresponding base model (re-instantiate to ensure fresh training)\n",
        "            if model_name == 'catboost':\n",
        "                 model = CatBoostRegressor(random_state=42, verbose=0)\n",
        "            elif model_name == 'ridge':\n",
        "                 model = Ridge(random_state=42)\n",
        "            elif model_name == 'lgbm':\n",
        "                 model = lgb.LGBMRegressor(random_state=42)\n",
        "            elif model_name == 'hgb':\n",
        "                 model = HistGradientBoostingRegressor(random_state=42)\n",
        "\n",
        "            # Train the model on the training fold\n",
        "            model.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "            # Make predictions on the validation fold\n",
        "            val_preds = model.predict(X_val_fold)\n",
        "\n",
        "            # Store the validation predictions in the OOF array\n",
        "            oof_preds[val_index] = val_preds\n",
        "\n",
        "        # Store the complete OOF predictions for the current model and blend property\n",
        "        oof_predictions[model_name][col] = oof_preds\n",
        "\n",
        "print(\"Out-of-fold prediction generation complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "402a760a"
      },
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "# Initialize a dictionary to store the trained Lasso meta-regressors\n",
        "meta_regressors = {}\n",
        "\n",
        "# Iterate through each blend property\n",
        "for col in y.columns:\n",
        "    print(f\"Training Lasso meta-regressor for {col}...\")\n",
        "\n",
        "    # Create a DataFrame of OOF predictions for the current blend property\n",
        "    oof_features = pd.DataFrame({\n",
        "        'catboost_oof': oof_predictions['catboost'][col],\n",
        "        'ridge_oof': oof_predictions['ridge'][col],\n",
        "        'lgbm_oof': oof_predictions['lgbm'][col],\n",
        "        'hgb_oof': oof_predictions['hgb'][col]\n",
        "    })\n",
        "\n",
        "    # Instantiate a Lasso meta-regressor\n",
        "    meta_model = Lasso(random_state=42)\n",
        "\n",
        "    # Fit the meta-regressor to the OOF predictions and the actual target values\n",
        "    meta_model.fit(oof_features, y[col])\n",
        "\n",
        "    # Store the trained meta-regressor\n",
        "    meta_regressors[col] = meta_model\n",
        "\n",
        "print(\"Lasso meta-regressor training complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9f0ac62c"
      },
      "source": [
        "# Initialize a dictionary to store test predictions from base models\n",
        "test_base_predictions = {}\n",
        "\n",
        "# Iterate through each base model and make predictions on the test data\n",
        "for model_name, models_dict in [('catboost', catboost_models),\n",
        "                                ('ridge', ridge_models),\n",
        "                                ('lgbm', lgbm_models),\n",
        "                                ('hgb', hgb_models)]:\n",
        "\n",
        "    test_base_predictions[model_name] = pd.DataFrame(test['ID']) # Initialize DataFrame with 'ID'\n",
        "\n",
        "    for col in y.columns:\n",
        "        model = models_dict[col]\n",
        "        test_base_predictions[model_name][col] = model.predict(X_test_engineered_summary)\n",
        "\n",
        "print(\"Test predictions from base models complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bccfd81"
      },
      "source": [
        "# Initialize a dictionary to store the final stacked predictions\n",
        "stacked_predictions = {}\n",
        "\n",
        "# Iterate through each blend property and make final predictions using the meta-regressor\n",
        "for col in y.columns:\n",
        "    print(f\"Making final stacked predictions for {col}...\")\n",
        "\n",
        "    # Create a DataFrame of test predictions from the base models for the current blend property\n",
        "    test_meta_features = pd.DataFrame({\n",
        "        'catboost_oof': test_base_predictions['catboost'][col],\n",
        "        'ridge_oof': test_base_predictions['ridge'][col],\n",
        "        'lgbm_oof': test_base_predictions['lgbm'][col],\n",
        "        'hgb_oof': test_base_predictions['hgb'][col]\n",
        "    })\n",
        "\n",
        "    # Get the corresponding trained meta-regressor\n",
        "    meta_model = meta_regressors[col]\n",
        "\n",
        "    # Make predictions using the meta-regressor\n",
        "    stacked_predictions[col] = meta_model.predict(test_meta_features)\n",
        "\n",
        "print(\"Final stacked predictions complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04f0f974"
      },
      "source": [
        "# Create a submission DataFrame using the test IDs\n",
        "submission_df = pd.DataFrame(test['ID'])\n",
        "\n",
        "# Add the stacked predictions to the submission DataFrame\n",
        "for col in stacked_predictions:\n",
        "    submission_df[col] = stacked_predictions[col]\n",
        "\n",
        "# Save the submission DataFrame to a CSV file\n",
        "submission_df.to_csv('submission_stacked_lasso.csv', index=False)\n",
        "\n",
        "print(\"Submission file 'submission_stacked_lasso.csv' created successfully!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27d4caef"
      },
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "# Initialize a dictionary to store the trained Ridge meta-regressors\n",
        "meta_regressors_ridge = {}\n",
        "\n",
        "# Iterate through each blend property\n",
        "for col in y.columns:\n",
        "    print(f\"Training Ridge meta-regressor for {col}...\")\n",
        "\n",
        "    # Create a DataFrame of OOF predictions for the current blend property\n",
        "    oof_features = pd.DataFrame({\n",
        "        'catboost_oof': oof_predictions['catboost'][col],\n",
        "        'ridge_oof': oof_predictions['ridge'][col],\n",
        "        'lgbm_oof': oof_predictions['lgbm'][col],\n",
        "        'hgb_oof': oof_predictions['hgb'][col]\n",
        "    })\n",
        "\n",
        "    # Instantiate a Ridge meta-regressor\n",
        "    meta_model = Ridge(random_state=42)\n",
        "\n",
        "    # Fit the meta-regressor to the OOF predictions and the actual target values\n",
        "    meta_model.fit(oof_features, y[col])\n",
        "\n",
        "    # Store the trained meta-regressor\n",
        "    meta_regressors_ridge[col] = meta_model\n",
        "\n",
        "print(\"Ridge meta-regressor training complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eee69e96"
      },
      "source": [
        "# Initialize a dictionary to store the final stacked predictions using Ridge meta-regressor\n",
        "stacked_predictions_ridge = {}\n",
        "\n",
        "# Iterate through each blend property and make final predictions using the Ridge meta-regressor\n",
        "for col in y.columns:\n",
        "    print(f\"Making final stacked predictions (Ridge meta-regressor) for {col}...\")\n",
        "\n",
        "    # Create a DataFrame of test predictions from the base models for the current blend property\n",
        "    test_meta_features = pd.DataFrame({\n",
        "        'catboost_oof': test_base_predictions['catboost'][col],\n",
        "        'ridge_oof': test_base_predictions['ridge'][col],\n",
        "        'lgbm_oof': test_base_predictions['lgbm'][col],\n",
        "        'hgb_oof': test_base_predictions['hgb'][col]\n",
        "    })\n",
        "\n",
        "    # Get the corresponding trained Ridge meta-regressor\n",
        "    meta_model = meta_regressors_ridge[col]\n",
        "\n",
        "    # Make predictions using the meta-regressor\n",
        "    stacked_predictions_ridge[col] = meta_model.predict(test_meta_features)\n",
        "\n",
        "print(\"Final stacked predictions (Ridge meta-regressor) complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5617f86f"
      },
      "source": [
        "# Create a submission DataFrame using the test IDs\n",
        "submission_df_ridge = pd.DataFrame(test['ID'])\n",
        "\n",
        "# Add the stacked predictions to the submission DataFrame\n",
        "for col in stacked_predictions_ridge:\n",
        "    submission_df_ridge[col] = stacked_predictions_ridge[col]\n",
        "\n",
        "# Save the submission DataFrame to a CSV file\n",
        "submission_df_ridge.to_csv('submission_stacked_ridge.csv', index=False)\n",
        "\n",
        "print(\"Submission file 'submission_stacked_ridge.csv' created successfully!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44019663"
      },
      "source": [
        "from sklearn.linear_model import ElasticNet\n",
        "\n",
        "# Initialize a dictionary to store the trained ElasticNet meta-regressors\n",
        "meta_regressors_elasticnet = {}\n",
        "\n",
        "# Iterate through each blend property\n",
        "for col in y.columns:\n",
        "    print(f\"Training ElasticNet meta-regressor for {col}...\")\n",
        "\n",
        "    # Create a DataFrame of OOF predictions for the current blend property\n",
        "    oof_features = pd.DataFrame({\n",
        "        'catboost_oof': oof_predictions['catboost'][col],\n",
        "        'ridge_oof': oof_predictions['ridge'][col],\n",
        "        'lgbm_oof': oof_predictions['lgbm'][col],\n",
        "        'hgb_oof': oof_predictions['hgb'][col]\n",
        "    })\n",
        "\n",
        "    # Instantiate an ElasticNet meta-regressor\n",
        "    meta_model = ElasticNet(random_state=42)\n",
        "\n",
        "    # Fit the meta-regressor to the OOF predictions and the actual target values\n",
        "    meta_model.fit(oof_features, y[col])\n",
        "\n",
        "    # Store the trained meta-regressor\n",
        "    meta_regressors_elasticnet[col] = meta_model\n",
        "\n",
        "print(\"ElasticNet meta-regressor training complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5f4af198"
      },
      "source": [
        "# Initialize a dictionary to store the final stacked predictions using ElasticNet meta-regressor\n",
        "stacked_predictions_elasticnet = {}\n",
        "\n",
        "# Iterate through each blend property and make final predictions using the ElasticNet meta-regressor\n",
        "for col in y.columns:\n",
        "    print(f\"Making final stacked predictions (ElasticNet meta-regressor) for {col}...\")\n",
        "\n",
        "    # Create a DataFrame of test predictions from the base models for the current blend property\n",
        "    test_meta_features = pd.DataFrame({\n",
        "        'catboost_oof': test_base_predictions['catboost'][col],\n",
        "        'ridge_oof': test_base_predictions['ridge'][col],\n",
        "        'lgbm_oof': test_base_predictions['lgbm'][col],\n",
        "        'hgb_oof': test_base_predictions['hgb'][col]\n",
        "    })\n",
        "\n",
        "    # Get the corresponding trained ElasticNet meta-regressor\n",
        "    meta_model = meta_regressors_elasticnet[col]\n",
        "\n",
        "    # Make predictions using the meta-regressor\n",
        "    stacked_predictions_elasticnet[col] = meta_model.predict(test_meta_features)\n",
        "\n",
        "print(\"Final stacked predictions (ElasticNet meta-regressor) complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfcb45b9"
      },
      "source": [
        "# Create a submission DataFrame using the test IDs\n",
        "submission_df_elasticnet = pd.DataFrame(test['ID'])\n",
        "\n",
        "# Add the stacked predictions to the submission DataFrame\n",
        "for col in stacked_predictions_elasticnet:\n",
        "    submission_df_elasticnet[col] = stacked_predictions_elasticnet[col]\n",
        "\n",
        "# Save the submission DataFrame to a CSV file\n",
        "submission_df_elasticnet.to_csv('submission_stacked_elasticnet.csv', index=False)\n",
        "\n",
        "print(\"Submission file 'submission_stacked_elasticnet.csv' created successfully!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83801fd1"
      },
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "# Initialize a dictionary to store the trained LightGBM meta-regressors\n",
        "meta_regressors_lgbm = {}\n",
        "\n",
        "# Iterate through each blend property\n",
        "for col in y.columns:\n",
        "    print(f\"Training LightGBM meta-regressor for {col}...\")\n",
        "\n",
        "    # Create a DataFrame of OOF predictions for the current blend property\n",
        "    oof_features = pd.DataFrame({\n",
        "        'catboost_oof': oof_predictions['catboost'][col],\n",
        "        'ridge_oof': oof_predictions['ridge'][col],\n",
        "        'lgbm_oof': oof_predictions['lgbm'][col],\n",
        "        'hgb_oof': oof_predictions['hgb'][col]\n",
        "    })\n",
        "\n",
        "    # Instantiate a LightGBM meta-regressor\n",
        "    meta_model = lgb.LGBMRegressor(random_state=42)\n",
        "\n",
        "    # Fit the meta-regressor to the OOF predictions and the actual target values\n",
        "    meta_model.fit(oof_features, y[col])\n",
        "\n",
        "    # Store the trained meta-regressor\n",
        "    meta_regressors_lgbm[col] = meta_model\n",
        "\n",
        "print(\"LightGBM meta-regressor training complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b17e1920"
      },
      "source": [
        "# Initialize a dictionary to store the final stacked predictions using LightGBM meta-regressor\n",
        "stacked_predictions_lgbm = {}\n",
        "\n",
        "# Iterate through each blend property and make final predictions using the LightGBM meta-regressor\n",
        "for col in y.columns:\n",
        "    print(f\"Making final stacked predictions (LightGBM meta-regressor) for {col}...\")\n",
        "\n",
        "    # Create a DataFrame of test predictions from the base models for the current blend property\n",
        "    test_meta_features = pd.DataFrame({\n",
        "        'catboost_oof': test_base_predictions['catboost'][col],\n",
        "        'ridge_oof': test_base_predictions['ridge'][col],\n",
        "        'lgbm_oof': test_base_predictions['lgbm'][col],\n",
        "        'hgb_oof': test_base_predictions['hgb'][col]\n",
        "    })\n",
        "\n",
        "    # Get the corresponding trained LightGBM meta-regressor\n",
        "    meta_model = meta_regressors_lgbm[col]\n",
        "\n",
        "    # Make predictions using the meta-regressor\n",
        "    stacked_predictions_lgbm[col] = meta_model.predict(test_meta_features)\n",
        "\n",
        "print(\"Final stacked predictions (LightGBM meta-regressor) complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7f8084d"
      },
      "source": [
        "# Create a submission DataFrame using the test IDs\n",
        "submission_df_lgbm_stacked = pd.DataFrame(test['ID'])\n",
        "\n",
        "# Add the stacked predictions to the submission DataFrame\n",
        "for col in stacked_predictions_lgbm:\n",
        "    submission_df_lgbm_stacked[col] = stacked_predictions_lgbm[col]\n",
        "\n",
        "# Save the submission DataFrame to a CSV file\n",
        "submission_df_lgbm_stacked.to_csv('submission_stacked_lgbm.csv', index=False)\n",
        "\n",
        "print(\"Submission file 'submission_stacked_lgbm.csv' created successfully!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "198f69e2"
      },
      "source": [
        "from catboost import CatBoostRegressor\n",
        "\n",
        "# Initialize a dictionary to store the trained CatBoost meta-regressors\n",
        "meta_regressors_catboost = {}\n",
        "\n",
        "# Iterate through each blend property\n",
        "for col in y.columns:\n",
        "    print(f\"Training CatBoost meta-regressor for {col}...\")\n",
        "\n",
        "    # Create a DataFrame of OOF predictions for the current blend property\n",
        "    oof_features = pd.DataFrame({\n",
        "        'catboost_oof': oof_predictions['catboost'][col],\n",
        "        'ridge_oof': oof_predictions['ridge'][col],\n",
        "        'lgbm_oof': oof_predictions['lgbm'][col],\n",
        "        'hgb_oof': oof_predictions['hgb'][col]\n",
        "    })\n",
        "\n",
        "    # Instantiate a CatBoost meta-regressor\n",
        "    meta_model = CatBoostRegressor(random_state=42, verbose=0) # verbose=0 to suppress output\n",
        "\n",
        "    # Fit the meta-regressor to the OOF predictions and the actual target values\n",
        "    meta_model.fit(oof_features, y[col])\n",
        "\n",
        "    # Store the trained meta-regressor\n",
        "    meta_regressors_catboost[col] = meta_model\n",
        "\n",
        "print(\"CatBoost meta-regressor training complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bd1cdceb"
      },
      "source": [
        "# Initialize a dictionary to store the final stacked predictions using CatBoost meta-regressor\n",
        "stacked_predictions_catboost = {}\n",
        "\n",
        "# Iterate through each blend property and make final predictions using the CatBoost meta-regressor\n",
        "for col in y.columns:\n",
        "    print(f\"Making final stacked predictions (CatBoost meta-regressor) for {col}...\")\n",
        "\n",
        "    # Create a DataFrame of test predictions from the base models for the current blend property\n",
        "    test_meta_features = pd.DataFrame({\n",
        "        'catboost_oof': test_base_predictions['catboost'][col],\n",
        "        'ridge_oof': test_base_predictions['ridge'][col],\n",
        "        'lgbm_oof': test_base_predictions['lgbm'][col],\n",
        "        'hgb_oof': test_base_predictions['hgb'][col]\n",
        "    })\n",
        "\n",
        "    # Get the corresponding trained CatBoost meta-regressor\n",
        "    meta_model = meta_regressors_catboost[col]\n",
        "\n",
        "    # Make predictions using the meta-regressor\n",
        "    stacked_predictions_catboost[col] = meta_model.predict(test_meta_features)\n",
        "\n",
        "print(\"Final stacked predictions (CatBoost meta-regressor) complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d228aeb"
      },
      "source": [
        "# Create a submission DataFrame using the test IDs\n",
        "submission_df_catboost = pd.DataFrame(test['ID'])\n",
        "\n",
        "# Add the stacked predictions to the submission DataFrame\n",
        "for col in stacked_predictions_catboost:\n",
        "    submission_df_catboost[col] = stacked_predictions_catboost[col]\n",
        "\n",
        "# Save the submission DataFrame to a CSV file\n",
        "submission_df_catboost.to_csv('submission_stacked_catboost.csv', index=False)\n",
        "\n",
        "print(\"Submission file 'submission_stacked_catboost.csv' created successfully!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9a1d2e47"
      },
      "source": [
        "# Initialize a dictionary to store predictions on full training data from base models\n",
        "train_base_predictions_full = {}\n",
        "\n",
        "# Iterate through each base model and make predictions on the full training data\n",
        "for model_name, models_dict in [('catboost', catboost_models),\n",
        "                                ('ridge', ridge_models),\n",
        "                                ('lgbm', lgbm_models),\n",
        "                                ('hgb', hgb_models)]:\n",
        "\n",
        "    train_base_predictions_full[model_name] = pd.DataFrame(y.index) # Initialize DataFrame with index\n",
        "\n",
        "    for col in y.columns:\n",
        "        model = models_dict[col]\n",
        "        train_base_predictions_full[model_name][col] = model.predict(X_train_engineered_summary)\n",
        "\n",
        "print(\"Predictions on full training data from base models complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acfc2541"
      },
      "source": [
        "from sklearn.linear_model import ElasticNet\n",
        "\n",
        "# Initialize a dictionary to store the trained ElasticNet meta-regressors\n",
        "meta_regressors_elasticnet_full_train = {}\n",
        "\n",
        "# Iterate through each blend property\n",
        "for col in y.columns:\n",
        "    print(f\"Training ElasticNet meta-regressor for {col} on full training data predictions...\")\n",
        "\n",
        "    # Create a DataFrame of full training data predictions for the current blend property\n",
        "    train_meta_features_full = pd.DataFrame({\n",
        "        'catboost_train_pred': train_base_predictions_full['catboost'][col],\n",
        "        'ridge_train_pred': train_base_predictions_full['ridge'][col],\n",
        "        'lgbm_train_pred': train_base_predictions_full['lgbm'][col],\n",
        "        'hgb_train_pred': train_base_predictions_full['hgb'][col]\n",
        "    })\n",
        "\n",
        "    # Instantiate an ElasticNet meta-regressor\n",
        "    meta_model = ElasticNet(random_state=42)\n",
        "\n",
        "    # Fit the meta-regressor to the full training data predictions and the actual target values\n",
        "    meta_model.fit(train_meta_features_full, y[col])\n",
        "\n",
        "    # Store the trained meta-regressor\n",
        "    meta_regressors_elasticnet_full_train[col] = meta_model\n",
        "\n",
        "print(\"ElasticNet meta-regressor training on full training data predictions complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bc4f8150"
      },
      "source": [
        "# Initialize a dictionary to store the final stacked predictions using ElasticNet meta-regressor trained on full training data\n",
        "stacked_predictions_elasticnet_full_train = {}\n",
        "\n",
        "# Iterate through each blend property and make final predictions using the ElasticNet meta-regressor\n",
        "for col in y.columns:\n",
        "    print(f\"Making final stacked predictions (ElasticNet meta-regressor full training) for {col}...\")\n",
        "\n",
        "    # Create a DataFrame of test predictions from the base models for the current blend property\n",
        "    test_meta_features_full = pd.DataFrame({\n",
        "        'catboost_train_pred': test_base_predictions['catboost'][col],\n",
        "        'ridge_train_pred': test_base_predictions['ridge'][col],\n",
        "        'lgbm_train_pred': test_base_predictions['lgbm'][col],\n",
        "        'hgb_train_pred': test_base_predictions['hgb'][col]\n",
        "    })\n",
        "\n",
        "    # Get the corresponding trained ElasticNet meta-regressor\n",
        "    meta_model = meta_regressors_elasticnet_full_train[col]\n",
        "\n",
        "    # Make predictions using the meta-regressor\n",
        "    stacked_predictions_elasticnet_full_train[col] = meta_model.predict(test_meta_features_full)\n",
        "\n",
        "print(\"Final stacked predictions (ElasticNet meta-regressor full training) complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eb9e50bf"
      },
      "source": [
        "# Create a submission DataFrame using the test IDs\n",
        "submission_df_elasticnet_full_train = pd.DataFrame(test['ID'])\n",
        "\n",
        "# Add the stacked predictions to the submission DataFrame\n",
        "for col in stacked_predictions_elasticnet_full_train:\n",
        "    submission_df_elasticnet_full_train[col] = stacked_predictions_elasticnet_full_train[col]\n",
        "\n",
        "# Save the submission DataFrame to a CSV file\n",
        "submission_df_elasticnet_full_train.to_csv('submission_stacked_elasticnet_full_train.csv', index=False)\n",
        "\n",
        "print(\"Submission file 'submission_stacked_elasticnet_full_train.csv' created successfully!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cd52466e"
      },
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "# Initialize a dictionary to store the trained Ridge meta-regressors\n",
        "meta_regressors_ridge_full_train = {}\n",
        "\n",
        "# Iterate through each blend property\n",
        "for col in y.columns:\n",
        "    print(f\"Training Ridge meta-regressor for {col} on full training data predictions...\")\n",
        "\n",
        "    # Create a DataFrame of full training data predictions for the current blend property\n",
        "    train_meta_features_full = pd.DataFrame({\n",
        "        'catboost_train_pred': train_base_predictions_full['catboost'][col],\n",
        "        'ridge_train_pred': train_base_predictions_full['ridge'][col],\n",
        "        'lgbm_train_pred': train_base_predictions_full['lgbm'][col],\n",
        "        'hgb_train_pred': train_base_predictions_full['hgb'][col]\n",
        "    })\n",
        "\n",
        "    # Instantiate a Ridge meta-regressor\n",
        "    meta_model = Ridge(random_state=42)\n",
        "\n",
        "    # Fit the meta-regressor to the full training data predictions and the actual target values\n",
        "    meta_model.fit(train_meta_features_full, y[col])\n",
        "\n",
        "    # Store the trained meta-regressor\n",
        "    meta_regressors_ridge_full_train[col] = meta_model\n",
        "\n",
        "print(\"Ridge meta-regressor training on full training data predictions complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe23188f"
      },
      "source": [
        "# Initialize a dictionary to store the final stacked predictions using Ridge meta-regressor trained on full training data\n",
        "stacked_predictions_ridge_full_train = {}\n",
        "\n",
        "# Iterate through each blend property and make final predictions using the Ridge meta-regressor\n",
        "for col in y.columns:\n",
        "    print(f\"Making final stacked predictions (Ridge meta-regressor full training) for {col}...\")\n",
        "\n",
        "    # Create a DataFrame of test predictions from the base models for the current blend property\n",
        "    test_meta_features_full = pd.DataFrame({\n",
        "        'catboost_train_pred': test_base_predictions['catboost'][col],\n",
        "        'ridge_train_pred': test_base_predictions['ridge'][col],\n",
        "        'lgbm_train_pred': test_base_predictions['lgbm'][col],\n",
        "        'hgb_train_pred': test_base_predictions['hgb'][col]\n",
        "    })\n",
        "\n",
        "    # Get the corresponding trained Ridge meta-regressor\n",
        "    meta_model = meta_regressors_ridge_full_train[col]\n",
        "\n",
        "    # Make predictions using the meta-regressor\n",
        "    stacked_predictions_ridge_full_train[col] = meta_model.predict(test_meta_features_full)\n",
        "\n",
        "print(\"Final stacked predictions (Ridge meta-regressor full training) complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7a89277"
      },
      "source": [
        "# Create a submission DataFrame using the test IDs\n",
        "submission_df_ridge_full_train = pd.DataFrame(test['ID'])\n",
        "\n",
        "# Add the stacked predictions to the submission DataFrame\n",
        "for col in stacked_predictions_ridge_full_train:\n",
        "    submission_df_ridge_full_train[col] = stacked_predictions_ridge_full_train[col]\n",
        "\n",
        "# Save the submission DataFrame to a CSV file\n",
        "submission_df_ridge_full_train.to_csv('submission_stacked_ridge_full_train.csv', index=False)\n",
        "\n",
        "print(\"Submission file 'submission_stacked_ridge_full_train.csv' created successfully!\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}